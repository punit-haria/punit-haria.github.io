<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on PS Musing</title>
    <link>https://punit-haria.github.io/posts/</link>
    <description>Recent content in Posts on PS Musing</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>&amp;copy; &lt;a href=&#34;https://github.com/punit-haria&#34;&gt;Punit Shah&lt;/a&gt; 2017</copyright>
    <lastBuildDate>Tue, 15 May 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://punit-haria.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Multimodal Example using Images</title>
      <link>https://punit-haria.github.io/posts/multimodal_example/</link>
      <pubDate>Tue, 15 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://punit-haria.github.io/posts/multimodal_example/</guid>
      <description>Previously, I described the general multimodal learning problem, outlined semi-supervised and unsupervised versions of the problem, and how one could approach them using deep generative models. The focus here is on illustrating these ideas with an example.
Colored MNIST The toy dataset we use in our experiments is built by taking deterministic transforms of MNIST to craft two separate modalities. For the first group, we paint each digit randomly using one of three colours, and for the second group, we apply a Sobel filter to extract an edge map of each digit and then paint each digit using one of three colours.</description>
    </item>
    
    <item>
      <title>Multimodal Learning</title>
      <link>https://punit-haria.github.io/posts/multimodal/</link>
      <pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://punit-haria.github.io/posts/multimodal/</guid>
      <description>Animals use their different sensory organs in synchrony to learn from and react to the environment. In a similar vein, to build truly intelligent systems, we need to leverage data in many forms. For example, in healthcare, electronic medical records and related patient data can take shape anywhere on the spectrum from medical imaging to high-frequency time series to adhoc doctors&#39; notes. There are many approaches to integrating data: we could concatenate different modalities in an end-to-end learning pipeline, or we can train separate learners on each modality and later fuse them via voting or averaging, or we can do some combination thereof.</description>
    </item>
    
    <item>
      <title>Variational Autoencoder</title>
      <link>https://punit-haria.github.io/posts/vae/</link>
      <pubDate>Sat, 13 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://punit-haria.github.io/posts/vae/</guid>
      <description>A previous post described how the linear Gaussian model provides a unified perspective for a host of unsupervised learning methods. The commonality across these methods is the linear relationship between the observed and latent (or hidden) variables. But when working with high-dimensional, composite data (e.g. natural images, video, language), we&amp;rsquo;d rather not restrict ourselves to a linear model. Instead, we want a model that can capture complex interactions between the observation and latent space.</description>
    </item>
    
    <item>
      <title>Textual Entailment</title>
      <link>https://punit-haria.github.io/posts/textual_entailment/</link>
      <pubDate>Fri, 08 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://punit-haria.github.io/posts/textual_entailment/</guid>
      <description>Storytelling is inherent to our nature and is found in almost every human endeavor: speech, literature, film, theatre, music, the visual arts, and journalism, to name a few. At the earliest of ages, we are attuned to and even crave the experience of a good story, and crucially, they drive our development. They guide us, teach us about our histories and cultures, and shape us as we form our identities. In listening to and learning from these stories, we build on our innate ability to ground the words and symbols we perceive into the complex world around us.</description>
    </item>
    
    <item>
      <title>Linear Gaussian Models</title>
      <link>https://punit-haria.github.io/posts/linear-models/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://punit-haria.github.io/posts/linear-models/</guid>
      <description>One set of unsupervised methods has stood the test of time, having widespread use across many fields: factor analysis, principal component analysis (PCA), Gaussian mixture models, vector quantization, Kalman filters, and hidden Markov models (HMMs). Factor analysis tries to explain the variance among observations using a smaller set of unobserved (or latent) factors. It&amp;rsquo;s applicability is far-reaching, with examples in psychometrics, microbiology, and marketing. PCA transforms a set of observations into a smaller set of uncorrelated variables, usually being the go-to first step in dimensionality reduction for most datasets.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://punit-haria.github.io/posts/about/</link>
      <pubDate>Sat, 10 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://punit-haria.github.io/posts/about/</guid>
      <description>Hi! My name is Punit. I&amp;rsquo;m interested in many aspects of machine learning and statistics, some of which are variational inference, multimodality, and reinforcement learning. Here, I&amp;rsquo;d like to explore different concepts through writing with the aim of separating what I know from what I think I know.
 </description>
    </item>
    
  </channel>
</rss>
