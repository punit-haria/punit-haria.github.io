<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"  lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Variational Autoencoder | PS Musing</title>

<meta property='og:title' content='Variational Autoencoder - PS Musing'>
<meta property='og:description' content='A previous post described how the linear Gaussian model provides a unified perspective for a host of unsupervised learning methods. The commonality across these methods is the linear relationship between the observed and latent (or hidden) variables. But when working with high-dimensional, composite data (e.g. natural images, video, language), we&rsquo;d rather not restrict ourselves to a linear model. Instead, we want a model that can capture complex interactions between the observation and latent space.'>
<meta property='og:url' content='https://punit-haria.github.io/posts/vae/'>
<meta property='og:site_name' content='PS Musing'>
<meta property='og:type' content='article'><meta property='og:image' content='https://www.gravatar.com/avatar/76d14f306d44ac5c6b2d010fef6889ce?s=256'><meta property='article:section' content='Posts'><meta property='article:published_time' content='2018-01-13T00:00:00Z'><meta property='article:modified_time' content='2018-01-13T00:00:00Z'><meta name='twitter:card' content='summary'><meta name='twitter:site' content='@sh_punit'><meta name='twitter:creator' content='@sh_punit'>


<link href="https://punit-haria.github.io/index.xml" rel="alternate" type="application/rss+xml" title="PS Musing">

<link rel="stylesheet" href="/css/style.css"><link rel='stylesheet' href='https://punit-haria.github.io/css/custom.css'><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<link rel="canonical" href="https://punit-haria.github.io/posts/vae/">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>

<section class="section">
  <div class="container">
    <nav id="nav-main" class="nav">
      <div id="nav-name" class="nav-left">
        <a id="nav-anchor" class="nav-item" href="https://punit-haria.github.io/">
          <h1 id="nav-heading" class="title is-4">PS Musing</h1>
        </a>
      </div>
      <div class="nav-right">
        <nav id="nav-items" class="nav-item level is-mobile"><a class="level-item" aria-label="github" href='https://github.com/punit-haria'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/>
    
  </svg></i>
            </span>
          </a><a class="level-item" aria-label="twitter" href='https://twitter.com/sh_punit'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"/>
    
  </svg></i>
            </span>
          </a><a class="level-item" aria-label="email" href='mailto:shahpunit@google.com'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/>
    <polyline points="22,6 12,13 2,6"/>
    
  </svg></i>
            </span>
          </a><a class="level-item" aria-label="linkedin" href='https://linkedin.com/in/punitharia'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path stroke-width="1.8" d="m5.839218,4.101561c0,1.211972 -0.974141,2.194011 -2.176459,2.194011s-2.176459,-0.982039 -2.176459,-2.194011c0,-1.211094 0.974141,-2.194011 2.176459,-2.194011s2.176459,0.982917 2.176459,2.194011zm0.017552,3.94922l-4.388022,0l0,14.04167l4.388022,0l0,-14.04167zm7.005038,0l-4.359939,0l0,14.04167l4.360816,0l0,-7.370999c0,-4.098413 5.291077,-4.433657 5.291077,0l0,7.370999l4.377491,0l0,-8.89101c0,-6.915523 -7.829986,-6.66365 -9.669445,-3.259423l0,-1.891237z"/>
    
  </svg></i>
            </span>
          </a></nav>
      </div>
    </nav>

    <nav class="nav">
      

      
    </nav>

  </div>
  <script src="/js/navicon-shift.js"></script>
</section>
<section class="section">
  <div class="container">
    <div class="subtitle tags is-6 is-pulled-right">
      
    </div>
    <h2 class="subtitle is-6">January 13, 2018</h2>
    <h1 class="title">Variational Autoencoder</h1>
    
    <div class="content">
      <p>A <a href="/posts/linear-models">previous post</a> described how the linear Gaussian model provides a unified perspective for a host of unsupervised learning methods. The commonality across these methods is the linear relationship between the observed and latent (or hidden) variables. But when working with high-dimensional, composite data (e.g. natural images, video, language), we&rsquo;d rather not restrict ourselves to a linear model. Instead, we want a model that can capture complex interactions between the observation and latent space. <a href="https://arxiv.org/abs/1312.6114">Kingma and Welling (2013)</a> introduce a learning algorithm that facilitates exactly this kind of modeling flexibility, and apply it to what they call the variational autoencoder.</p>
<p>In the linear Gaussian model, the conditional likelihood is defined to be $p(\mathbf{y}\vert\mathbf{x}) = \mathcal{N}(\mathbf{y}\vert \mathbf{Cx}, \mathbf{R})$. The likelihood distribution is Gaussian, with mean $\boldsymbol{\mu} = \mathbf{Cx}$. In other words, the mean is a linear transform of the latent variable. We can generalize this in the following way:</p>

$$p_{\theta}(\mathbf{y} \vert \mathbf{x}) = \mathcal{N}(\mathbf{y}\vert \boldsymbol{\mu}_{\theta}(\mathbf{x}), \mathbf{\Sigma}_{\theta}(\mathbf{x})).$$

<p>Here the functions $\boldsymbol{\mu}_{\theta}(\cdot)$ and $\mathbf{\Sigma}_{\theta}(\cdot)$ can be arbitrary nonlinear functions of the latent variable, parameterized by a set of model parameters $\theta$. We similarly parameterize the prior distribution, $p_{\theta}(\mathbf{x})$. The learning problem is now to find parameter settings which maximize the marginal likelihood $p_{\theta}(\mathbf{y}) = \int p_{\theta} (\mathbf{x}, \mathbf{y}) d \mathbf{x}$.</p>
<p>Sounds straightforward, right? Not quite. The problem we now face is in choosing $\boldsymbol{\mu}_{\theta}(\cdot)$ and $\mathbf{\Sigma}_{\theta}(\cdot)$ such that the learning process remains tractable and efficient. One way to proceed is to use deep neural networks, as is described in the paper. Without going into too much detail, let&rsquo;s think of deep networks simply as mappings $f : \mathcal{U} \rightarrow \mathcal{V}$ built using compositions of linear transforms and nonlinear functions. They are designed to be differentiable almost everywhere, making them compatible with gradient-based optimization methods, giving us a chance at tractable inference and learning.</p>
<h3 id="variational-methods">Variational Methods</h3>
<p>In order to leverage efficient gradient-based learning, we need to transform our problem of evaluating the integral in the marginal likelihood into a tractable optimization problem. <em>Variational methods</em> do exactly this. The idea is to define a lower-bound on the log-marginal which can be efficiently optimized. The hope is that a sufficiently tight bound on the log-marginal will emerge. Although the optimization process typically converges, there is no clear way to predict how close the bound is to the true maximum likelihood solution. Nevertheless, variational methods perform well in practice, especially with larger datasets.</p>
<p>To construct a lower bound, we use one outcome of <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen&rsquo;s inequality</a> which states that $\log \mathbb{E}[f(\mathbf{x})] \geq \mathbb{E}[\log f(\mathbf{x})]$ for a function $f$. We also define a <em>variational distribution</em> $q(\mathbf{x}\vert \mathbf{y})$. A lower bound is derived in the following way:</p>

$$
\begin{aligned} \log p(\mathbf{y}) \ &= \ \log \int \frac{p_{\theta}(\mathbf{y}, \mathbf{x})}{q(\mathbf{x} \vert \mathbf{y})} q(\mathbf{x}\vert \mathbf{y})  d \mathbf{x} \\ &= \  \log \mathbb{E}_{q(\mathbf{x}\vert \mathbf{y})} \bigg[ \frac{p_{\theta}(\mathbf{y}, \mathbf{x})}{q(\mathbf{x} \vert \mathbf{y})} \bigg] \\ &\geq  \ \mathbb{E}_{q(\mathbf{x}\vert \mathbf{y})} \bigg[ \log \frac{p_{\theta}(\mathbf{y}, \mathbf{x})}{q(\mathbf{x} \vert \mathbf{y})} \bigg] \ =: \ \mathcal{F}. \end{aligned}
$$

<p>Here we introduced the variational distribution into the numerator and denominator, in order to reformulate the log-marginal as an expectation. We then apply Jensen&rsquo;s inequality to derive a lower bound. The name of the game is now to optimize the lower bound $\mathcal{F}$ with respect to both the parameter set $\theta$ and the variational distribution $q$. The general problem of optimizing with respect to a function is the domain of the calculus of variations, which is why this approach is referred to as a <em>variational</em> method.</p>
<h3 id="the-kl-divergence">The KL-Divergence</h3>
<p>The lower bound we derived above may come off as a little bit arbitrary. But consider the following reformulation:</p>

$$
\begin{aligned} \mathcal{F} \ &= \ \log p(\mathbf{y}) + \mathbb{E}_{q(\mathbf{x}\vert \mathbf{y})} \bigg[ \log \frac{p(\mathbf{x} \vert \mathbf{y})}{q(\mathbf{x} \vert \mathbf{y})} \bigg]  \\    &= \ \log p(\mathbf{y}) - \text{KL}[q(\mathbf{x} \vert \mathbf{y})  \vert \vert p(\mathbf{x} \vert \mathbf{y}) ].\end{aligned}
$$

<p>Here $\text{KL}[q \vert \vert p]$ is known as the <em>KL-divergence</em>, having its roots in information theory. It is a measure of the proximity between distributions $q$ and $p$. We can use Jensen&rsquo;s inequality to show that it is nonnegative. Given this fact and the reformulation above, we see that the optimum with respect to $q$ is when $\text{KL}[q \vert \vert p] = 0,$  and this happens precisely when $q = p$. Therefore, maximizing $\mathcal{F}$ w.r.t. $q$ is equivalent to minimizing the KL-divergence, and in minimizing $\text{KL}[q \vert \vert p]$, we are making a better and better approximation $q(\mathbf{x} \vert \mathbf{y})$ to the posterior $p(\mathbf{x} \vert \mathbf{y})$.</p>
<h3 id="amortized-inference">Amortized Inference</h3>
<p>When we apply this variational method to a dataset of $n$ samples, we have to optimize $\mathcal{F}$ with respect to $\theta$ and each of $q_1, \ldots, q_n$. This cannot scale to large datasets. So instead of having a separate variational distribution for each data point, we can parameterize a single distribution: $q_{\phi}(\mathbf{x}\vert \mathbf{y})$. Here $\phi$ are the variational parameters, and we have in effect <em>amortized</em> the inference procedure. Now the optimization problem is to maximize $\mathcal{F}$ with respect to the model parameters $\theta$ and the variational parameters $\phi$. This approach is computationally efficient and scales to large datasets. Note we can incorporate deep neural networks in the variational distribution as well!</p>
<h3 id="the-reparameterization-trick">The Reparameterization Trick</h3>
<p>Let&rsquo;s quickly summarize what we&rsquo;ve done. A difficult integration problem has been transformed into a (possibly) tractable optimization problem, which is to maximize the lower bound:</p>

$$ \mathcal{F}(\theta, \phi) \ = \ \mathbb{E}_{q_{\phi}} \bigg[ \log \frac{p_{\theta}(\mathbf{x}, \mathbf{y})}{q_{\phi}(\mathbf{x} \vert \mathbf{y})} \bigg]. $$

<p>The next step is to optimize this bound using stochastic gradient descent. However, we&rsquo;ve hit one more obstacle in our path to efficient inference. Notice that the expectation above is with respect to the variational distribution, which is itself parameterized by $\phi$. This means that we can&rsquo;t quite differentiate with respect to $\phi$.</p>
<p>The troublesome differentiation problem above is equivalent to differentiating $\mathbb{E}_{q_{\phi}(\mathbf{x})}[f(\mathbf{x})]$ with respect to $\phi$, for some function $f.$ If we try to approximate the problematic expectation using a Monte Carlo estimate, we get something like: $\mathbb{E}_{q_{\phi}(\mathbf{x})}[f(\mathbf{x})] \approx \frac{1}{S} \sum_{j=1}^S f(\mathbf{x})$. Unfortunately this doesn&rsquo;t work in its naive form because the expectation is with respect to a function of the variational parameters $\phi$.</p>
<p>Here <a href="https://arxiv.org/abs/1312.6114">Kingma and Welling (2013)</a> introduce a clever work-around known as the reparameterization trick. The idea is quite simple and has often been used in other contexts. The strategy is to divorce the stochastic nature of $\mathbf{x}$ from the parameters $\phi$. We define the latent variable $\mathbf{x} \sim q_{\phi}(\mathbf{x} \vert \mathbf{y})$ using a transformation $\mathbf{x} = g_{\phi}(\mathbf{y}, \boldsymbol{\epsilon})$, where $\boldsymbol{\epsilon} \sim p(\boldsymbol{\epsilon})$. Our previous Monte Carlo estimate now becomes:</p>

$$ \mathbb{E}_{q_{\phi}(\mathbf{x})} [f(\mathbf{x})]  \ = \ \mathbb{E}_{p(\boldsymbol{\epsilon})} [ f(g_{\phi}(\mathbf{y}, \boldsymbol{\epsilon}))] \ \approx \ \frac{1}{S} \sum_{j=1}^S f(g_{\phi}(\mathbf{y}, \boldsymbol{\epsilon}^{(j)})),$$ 

<p>where each $\boldsymbol{\epsilon}^{(j)}$ is a sample from $p(\boldsymbol{\epsilon})$. As long as $g$ is differentiable, we can differentiate with respect to $\phi$ using this estimate. However, note that this approach can only be used for continuous latent variables because of the differentiability requirement (an alternative approach that works for discrete $\mathbf{x}$ is known as the <a href="http://blog.shakirm.com/2015/11/machine-learning-trick-of-the-day-5-log-derivative-trick/">score function estimator</a>).</p>
<p>The paper proposes a few different ways to choose the function $g$ and the distribution $p(\boldsymbol{\epsilon})$. The one I&rsquo;ll highlight for the purpose of this post is the location-scale transform, especially since we&rsquo;ve been working with Gaussians. First, lets say that our prior distribution is a Gaussian with spherical covariance: $p(\mathbf{x}) = \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\sigma}^2 \mathbf{I})$. Then we can set $\mathbf{x} = g(\boldsymbol{\epsilon}) = \boldsymbol{\mu} + \boldsymbol{\sigma} \odot \boldsymbol{\epsilon}$, and $\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$. Here the $\odot$ operator is just element-wise multiplication. The distribution parameters $\boldsymbol{\mu}$ and $\boldsymbol{\sigma}$ are functions parameterized by $\phi$, and we have in effect separated the stochasticity in $\mathbf{x}$ from the parameters $\phi$.</p>
<p>Putting all this together, our optimization problem is now:</p>

$$ \text{max}_{\phi, \theta} \bigg\{  \frac{1}{S} \sum_{j=1}^S  \log \frac{p_{\theta}(\mathbf{y}, \mathbf{x}^{(j)})}{q_{\phi}(\mathbf{x}^{(j)} \vert \mathbf{y})}  \bigg \} $$

<p>where $\mathbf{x}^{(j)} = \boldsymbol{\mu} + \boldsymbol{\sigma} \odot \boldsymbol{\epsilon}^{(j)}$ and $\boldsymbol{\epsilon}^{(j)} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$, for $j = 1, \ldots, S$. For the purposes of this discussion, I have applied the Monte Carlo estimate to all parts of the expectation. However, we may not always need to do this. In fact, for this specific model, the KL-divergence term can be computed analytically (see the <a href="https://arxiv.org/abs/1312.6114">paper&rsquo;s</a> appendix).</p>
<h3 id="the-variational-autoencoder">The Variational Autoencoder</h3>
<p>When we combine the above inference and learning procedure with neural networks, we get the variational autoencoder. In this section, we describe one realization of this model. In many cases, the purpose of our latent variable model is to infer simpler, lower-dimensional representations of the observed data. While the data distribution $p(\mathbf{y})$ may be incredibly complex, it is reasonable to use a simple prior on the latent variable:  $p(\mathbf{x}) = \mathcal{N}(\mathbf{0}, \mathbf{I})$. For this discussion, let&rsquo;s suppose we have continuous observations, and we think that a Gaussian might be a reasonable assumption: $p_{\theta}(\mathbf{y} \vert \mathbf{x}) = \mathcal{N}(\mathbf{y}\vert \boldsymbol{\mu}_{\theta}(\mathbf{x}), \mathbf{\sigma}_{\theta}^2(\mathbf{x}) \mathbf{I})$. Here we have assumed that a diagonal covariance suffices, but there is nothing stopping us from using a richer covariance function.</p>
<p>The functions $\boldsymbol{\mu}_{\theta}(\mathbf{x})$ and $\mathbf{\sigma}_{\theta}(\mathbf{x})$ are feed-forward neural networks, and $\theta$ denotes their parameters. Typically, the two networks may share certain parameters or layers. The variational distribution is defined similarly: $q_{\phi}(\mathbf{x} \vert \mathbf{y}) = \mathcal{N}(\mathbf{x}\vert \boldsymbol{\mu}_{\phi}(\mathbf{y}), \mathbf{\sigma}_{\phi}^2(\mathbf{y}) \mathbf{I})$, and again parameterized by feed-forward neural networks with parameters $\phi$. You may now start to see why this model is known as a variational <em>autoencoder</em>. The variational distribution is parameterized by a network which <em>encodes</em> the observation, while the conditional likelihood is parameterized by a network which <em>decodes</em> $\mathbf{y}$ from the latent space. Hence, this is very much an <a href="https://en.wikipedia.org/wiki/Autoencoder">autoencoder</a> flavour.</p>
<p>Learning can be done using gradient-based approaches, and in particular, we can use a stochastic gradient method to scale our approach to very large datasets. The figure below depicts test samples from the MNIST dataset, and compares them with data generated from a variational autoencoder (see Tensorflow implementation <a href="https://github.com/punit-haria/multimodal-learning/blob/master/code/models/vae.py">here</a>).</p>
<figure class="center">
	<img src="/img/aevb/test.png" style="float: left; width:30%; margin-left: 10%; margin-right: 20%">
	<img src="/img/aevb/model.png" style="float: left; width:30%; margin-right: 10%">
	<p style="clear: both;"></p>
    <figcaption>
		  <h6>Left: Samples from MNIST test set. Right: Synthetic samples from a variational autoencoder.</h6>
    </figcaption>
</figure>

<p>So what do we get from all this? Well, we have a scalable probabilistic unsupervised model which can only improve as progress is made in deep learning, i.e. with better architectures, optimization methods, etc. We&rsquo;re able to infer lower-dimensional representations of complex data modalities, and unlike vanilla autoencoders, we have a means to reason about our uncertainty in these representations. We also have a generative model through which we can produce synthetic data.</p>

      
      <div class="related">
</div>
      
    </div>
    
  </div>
</section>



<section class="section">
  <div class="container has-text-centered">
    <p>&copy; <a href="https://github.com/punit-haria">Punit Shah</a> 2017</p>
    
      <p>Powered by <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/ribice/kiss">Kiss</a>.</p>
    
  </div>
</section>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-187493056-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>





</body>
</html>

