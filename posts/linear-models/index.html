<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"  lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Linear Models | ML is just Stats ;)</title>

<meta property='og:title' content='Linear Models - ML is just Stats ;)'>
<meta property='og:description' content='Several methods for unsupervised learning have seen ubiquitous use, past and present, across many scientific communities. These include factor analysis, principal component analysis (PCA), Gaussian mixture models, vector quantization, Kalman filters, and hidden Markov models (HMMs). In this post, I outline how these methods can be unified into a single framework, as is shown in the classic Roweis and Ghahramani (1999) paper.
Factor analysis is a method for explaining the variance among observations using a smaller set of unobserved (or latent) factors.'>
<meta property='og:url' content='https://punit-haria.github.io/posts/linear-models/'>
<meta property='og:site_name' content='ML is just Stats ;)'>
<meta property='og:type' content='article'><meta property='og:image' content='https://www.gravatar.com/avatar/76d14f306d44ac5c6b2d010fef6889ce?s=256'><meta property='article:section' content='Posts'><meta property='article:published_time' content='2017-11-17T00:00:00Z'><meta property='article:modified_time' content='2017-11-17T00:00:00Z'><meta name='twitter:card' content='summary'><meta name='twitter:site' content='@twitter'><meta name='twitter:creator' content='@twitter'>


<link href="https://punit-haria.github.io/index.xml" rel="alternate" type="application/rss+xml" title="ML is just Stats ;)">

<link rel="stylesheet" href="/css/style.css"><link rel='stylesheet' href='https://punit-haria.github.io/css/custom.css'><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<link rel="canonical" href="https://punit-haria.github.io/posts/linear-models/">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>
<section class="section">
  <div class="container">
    <nav id="nav-main" class="nav">
      <div id="nav-name" class="nav-left">
        <a id="nav-anchor" class="nav-item" href="https://punit-haria.github.io/">
          <h1 id="nav-heading" class="title is-4">ML is just Stats ;)</h1>
        </a>
      </div>
      <div class="nav-right">
        <nav id="nav-items" class="nav-item level is-mobile"><a class="level-item" aria-label="github" href='https://github.com/punit-haria'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/>
    
  </svg></i>
            </span>
          </a><a class="level-item" aria-label="twitter" href='https://twitter.com/twitter'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"/>
    
  </svg></i>
            </span>
          </a><a class="level-item" aria-label="email" href='mailto:shahpunit@google.com'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/>
    <polyline points="22,6 12,13 2,6"/>
    
  </svg></i>
            </span>
          </a><a class="level-item" aria-label="linkedin" href='https://linkedin.com/in/punitharia'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path stroke-width="1.8" d="m5.839218,4.101561c0,1.211972 -0.974141,2.194011 -2.176459,2.194011s-2.176459,-0.982039 -2.176459,-2.194011c0,-1.211094 0.974141,-2.194011 2.176459,-2.194011s2.176459,0.982917 2.176459,2.194011zm0.017552,3.94922l-4.388022,0l0,14.04167l4.388022,0l0,-14.04167zm7.005038,0l-4.359939,0l0,14.04167l4.360816,0l0,-7.370999c0,-4.098413 5.291077,-4.433657 5.291077,0l0,7.370999l4.377491,0l0,-8.89101c0,-6.915523 -7.829986,-6.66365 -9.669445,-3.259423l0,-1.891237z"/>
    
  </svg></i>
            </span>
          </a></nav>
      </div>
    </nav>

    <nav class="nav">
      

      
    </nav>

  </div>
  <script src="/js/navicon-shift.js"></script>
</section>
<section class="section">
  <div class="container">
    <div class="subtitle tags is-6 is-pulled-right">
      
    </div>
    <h2 class="subtitle is-6">November 17, 2017</h2>
    <h1 class="title">Linear Models</h1>
    
    <div class="content">
      <p>Several methods for unsupervised learning have seen ubiquitous use, past and present, across many scientific communities. These include factor analysis, principal component analysis (PCA), Gaussian mixture models, vector quantization, Kalman filters, and hidden Markov models (HMMs). In this post, I outline how these methods can be unified into a single framework, as is shown in the classic <a href="https://doi.org/10.1162/089976699300016674">Roweis and Ghahramani (1999)</a> paper.</p>
<p>Factor analysis is a method for explaining the variance among observations using a smaller set of unobserved (or latent) factors. It is often used in the fields of psychology, finance, and biology, and a noteworthy example is its use in determining the <a href="https://en.wikipedia.org/wiki/Big_Five_personality_traits">Big Five personality traits</a>. It has also been used to better understand human intelligence. The PCA algorithm is a related method for transforming a set of observations into a smaller set of uncorrelated variables. It sees widespread use in a variety of fields as the go-to dimensionality reduction method. Similarly, Kalman filter models and HMMs are ubiquitous in the signal processing, econometrics, and speech recognition communities. What all of these models and methods have in common, is that they relate a set of observations to another set of hidden variables. They have all proven to be significant ideas, showing wide applicability in a diverse range of fields.</p>
<p>Now this post is about using a single lens to view all of these methods. But first you might ask, why bother? One critical reason for drawing connections between these methods is to create a common language between the various scientific communities, and to encourage cross-disciplinary collaboration. The perspective consolidated and offered by Roweis and Ghahramani in their 1999 paper is a top-down look at how these methods are formed and how they relate to each other.</p>
<h3 id="the-model">The Model</h3>
<p>We begin with a discrete-time stochastic process $ \mathbf{x}_t $ which is represented at each timestep with a $k$-dimensional hidden state $ \mathbf{x} = (x_1, \ldots, x_k) $. This process may be describing the value of a financial instrument over time, or the quality of life in an assortment of cities, or the personality traits of a subpopulation of individuals. The central tenet is that the state $\mathbf{x}$ underlies a process that we want to understand, but cannot directly observe. Instead we go out into the world and make measurements ${\mathbf{y}_t}$ which we believe are related in some way to the hidden process we seek. This could be a collection of economic indicators, or questionnaire responses about life satisfaction, or self-reported assessments about personality. The idea is that they are measurable, and let&rsquo;s suppose they are $p$-dimensional: $ \mathbf{y} = (y_1, \ldots, y_p) $.</p>
<p>Now, how do we relate the observation to the hidden state? As a simple first step, we may assume that this relationship is linear. In statistics and machine learning, the linearity assumption tends to simplify <a href="#inference">inference and learning</a>. In addition, we may assume that the hidden process ${ \mathbf{x}_t }$ is <a href="https://en.wikipedia.org/wiki/Markov_chain">first-order Markovian</a>, meaning the state at each timestep only depends on the state at the previous timestep.</p>
<p>For a continuous-valued state variable $\mathbf{x}$, this means:</p>

$$
\begin{aligned} 
\mathbf{x}_{t+1} &= \mathbf{A} \mathbf{x}_t + \mathbf{w}_t \\\\\\ 
\mathbf{y}_t &= \mathbf{C} \mathbf{x}_t + \mathbf{v}_t  
\end{aligned}
$$

<p>Here $\mathbf{A}$ is the $k \times k$ state transition matrix, and $\mathbf{C}$ is the $p \times k$ observation matrix. The random vectors $\mathbf{w}_t$ and $\mathbf{v}_t$ correspond to temporally independent processes which add noise to the hidden and observation processes. Notice, that there is no direct temporal dependency between the observations. Instead, each observation depends only on the hidden state at that timestep, and again this dependency is linear.</p>
<p>We can visually depict the observation and hidden processes using the notation of graphical models. Here we have a directed acyclic graphical model which highlights the conditional dependency relationships.</p>
<figure class="center">
    <img src="/img/linear-gaussian/dynamic_model.png" width="50%"/> 
</figure>

<p>One final assumption is that the noise processes ${\mathbf{w}_t}$ and ${\mathbf{v}_t}$ are Gaussian-distributed with zero mean, i.e. $\mathbf{w}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{Q})$ and $\mathbf{v}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{R})$. Here $\mathbf{Q}$ and $\mathbf{R}$ are the respective covariance matrices. As with the assumption of linearity, Gaussian noise eases inference and learning in our model. Its use is also justified by the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem</a>.</p>
<p>What we have just described is known as a <strong>linear Gaussian model</strong>. It is a <em>generative model</em> where the hidden state $\mathbf{x}$ is first sampled from a distribution, and subsequently, the observation $\mathbf{y}$ is sampled from a distribution conditional on $\mathbf{x}$.  We refer to the matrices $\mathbf{A},  \mathbf{C}, \mathbf{Q},$ and $\mathbf{R}$ as the model&rsquo;s parameters. An analytic or algorithmic approach is used to <a href="#inference">learn</a> these parameters from a given set of observations. In the sections which follow, we will show how variations of this model lead to some commonly-used unsupervised learning methods.</p>
<hr>
<p><strong>A Few Details:</strong></p>
<ul>
<li>The &ldquo;zero mean&rdquo; assumption on the noise processes does not take away from our model. If we add an extra element to the state vector, fixed at unity, then we can correspondingly add an extra column to the transition matrix which will hold the (non-zero) mean. The same reasoning can be applied to the observation process.</li>
<li>Setting the covariance matrix $\mathbf{Q}$ to the identity does not take away from our model either. Since $\mathbf{Q}$ is positive semi-definite, we can take its eigendecomposition: $\mathbf{Q}= \mathbf{E}\mathbf{\Lambda}\mathbf{E}^T,$ where $\mathbf{E}$ is the orthogonal matrix of eigenvectors and $\mathbf{\Lambda}$ is the diagonal matrix of eigenvalues. If we redefine our model using a new state variable $\mathbf{x}' = \mathbf{\Lambda}^{-1/2} \mathbf{E}^T \mathbf{x},$ then $\text{Cov}(\mathbf{x}') = \mathbf{\Lambda}^{-1/2} \mathbf{E}^T \text{Cov}(\mathbf{x}) \mathbf{E} \mathbf{\Lambda}^{-1/2} = \mathbf{\Lambda}^{-1/2} \mathbf{E}^T \mathbf{Q} \mathbf{E} \mathbf{\Lambda}^{-1/2}  = \mathbf{I}.$ In this redefined model, the covariance parameter is the identity, and the structure in $\mathbf{Q}$ has moved to the matrices $\mathbf{A}' = \mathbf{A} \mathbf{E} \mathbf{\Lambda}^{1/2}$ and $\mathbf{C}' = \mathbf{C} \mathbf{E} \mathbf{\Lambda}^{1/2}.$</li>
<li>On the other hand, the matrix $\mathbf{R}$ cannot be redefined in the same way since we can&rsquo;t just rescale or whiten the observations.</li>
<li>The state sequence is usually a lower dimensional projection of the observation sequence, i.e. $k \ll p$. But sometimes we can have $k &gt; p$ where the idea is that the state variable is a compressed representation of a sequence of $\tau$ observations. For this to be valid, we require that $k \leq \tau p$.</li>
</ul>
<hr>
<h3 id="gaussian-properties">Gaussian Properties</h3>
<p>In this section, we briefly review some key Gaussian properties that drive inference and learning in our model. Two crucial things to note are that the sum of two Gaussian random variables is Gaussian-distributed, and that a linear transformation of a Gaussian random variable is also Gaussian-distributed. From these two properties, we see that if the initial state is Gaussian, i.e. $\mathbf{x}_1 \sim \mathcal{N}(\boldsymbol{\mu}_1, \mathbf{Q}_1)$, then all future states $\mathbf{x}_t$ and observations $\mathbf{y}_t$ will be Gaussian-distributed. More specifically, we have that:</p>

$$
\begin{aligned} 
p(\mathbf{x}_{t+1} \vert \mathbf{x}_t) &= \mathcal{N}(\mathbf{A}\mathbf{x}_t, \mathbf{Q}) \quad \text{and}  \\\\\\ 
p(\mathbf{y}_t \vert \mathbf{x}_t) &= \mathcal{N}(\mathbf{C}\mathbf{x}_t, \mathbf{R}).  
\end{aligned}
$$

<p>Additionally, the first-order Markov assumption allows us to decompose the joint distribution:</p>

$$
p(\mathbf{x}_1, \ldots, \mathbf{x}_{\tau}, \mathbf{y}_1, \ldots, \mathbf{y}_{\tau}) \ = \ p(\mathbf{x}_1) \prod_{t=1}^{\tau-1} p(\mathbf{x}_{t+1} \vert \mathbf{x}_t) \prod_{t=1}^{\tau} p(\mathbf{y}_t  \vert  \mathbf{x}_t).
$$

<p>Thus, the joint distribution is essentially a product of Gaussian distributions.</p>
<h3 id="a-nameinferenceainference-and-learning"><!-- raw HTML omitted --><!-- raw HTML omitted -->Inference and Learning</h3>
<p>The problem of <em>inference</em> is to ask the question: what can be inferred about the hidden process from a set of observations $\{\mathbf{y}_1, \ldots, \mathbf{y}_{\tau}\}$ and a fixed set of parameters ${\mathbf{A}, \mathbf{C}, \mathbf{Q}, \mathbf{R}, \boldsymbol{\mu}_1, \mathbf{Q}_1}$? What can we know about the current hidden state using <em>past</em> observations? We can directly answer this question because all our knowledge about the hidden state is encoded into the probability distribution: $p(\mathbf{x}_t \vert \mathbf{y}_1, \ldots, \mathbf{y}_t)$. Evaluating this quantity is known as <em>filtering</em>. We may also ask, what do we know about the hidden state from <em>both</em> past and future observations? In this case, the quantity we want is $p(\mathbf{x}_t \vert \mathbf{y}_1, \ldots, \mathbf{y}_{\tau})$, and this is referred to as <em>smoothing</em>. In the general case, computing either of these conditional distributions will make use of Bayes' theorem, which in turn requires that we compute the <strong>marginal likelihood</strong>:</p>

$$p(\mathbf{y}_1, \ldots, \mathbf{y}_{\tau}) \ = \ \int_{\mathbf{x}_1, \ldots, \mathbf{x}_{\tau}} p(\mathbf{x}_1, \ldots, \mathbf{x}_{\tau}, \mathbf{y}_1, \ldots, \mathbf{y}_{\tau}) \ d \{ \mathbf{x}_1, \ldots, \mathbf{x}_{\tau} \}$$ 

<p>This integral (or summation in the discrete case) is difficult, and many methods have been devised to solve or circumvent it. In most cases, evaluating the marginal likelihood is the crux of the inference problem.</p>
<p>The process of <em>learning</em> refers to any method which finds settings of the model parameters that maximize the marginal likelihood over the observed data. There are many approaches to learning, but it is particularly useful to understand the EM algorithm because it forms the basis for many other learning methods. It also provides a joint solution to both the inference and learning problems. I shall defer an explanation of the EM algorithm to a later time, and instead use this article to emphasize the relationships between the various unsupervised learning methods. Nevertheless, <a href="https://doi.org/10.1162/089976699300016674">Roweis and Ghahramani (1999)</a> provide a very clear exposition of the EM algorithm.</p>
<h3 id="kalman-filters-and-hmms">Kalman Filters and HMMs</h3>
<p>In this section, we show how variations of the linear Gaussian model above are equivalent to the Kalman filter (or linear dynamical system) and the hidden Markov model. In fact, the Kalman filter is exactly equivalent to our model specification above. Moreover, we can arrive at the HMM by making the following adjustment to the model:</p>

$$\begin{aligned} \mathbf{x}_{t+1} \ &= \ \text{WTA}[\mathbf{A} \mathbf{x}_t + \mathbf{w}_t]  \\ \mathbf{y}_{t} \ &= \ \mathbf{C} \mathbf{x}_t + \mathbf{v}_t \end{aligned}$$

<p>Here the $\text{WTA}[\cdot]$ operator is a vector with unity at the maximal element of the input, and zeros in all other positions. It is known as the <em>winner-take-all</em> nonlinearity. Hidden Markov models are based upon a discrete state-space, and the $\text{WTA}[\cdot]$ operator is a simple way of formalizing this in our linear Gaussian model. In our framework, the only difference between the Kalman filter and the HMM is the use of this operator.</p>
<h3 id="modeling-static-data">Modeling Static Data</h3>
<p>Static data refers to the case when our observations are not taken across time, but are instead independently drawn from some generating process. Factor analysis, PCA, mixtures of Gaussians, and vector quantization are all examples of static data models. If we set $\mathbf{A} = \mathbf{0}$ in our linear Gaussian model, we get the following:</p>
<p>$$\begin{aligned} \mathbf{x} \ &amp;= \ \mathbf{w} \ \mathbf{y} \ &amp;= \ \mathbf{C} \mathbf{x} + \mathbf{v} \end{aligned}$$</p>
<p>There is no temporal dependency, which means each $\mathbf{x}$ is Gaussian, i.e. $\mathbf{x} \sim \mathbf{w} \sim \mathcal{N}(\mathbf{0}, \mathbf{Q})$. The figure below graphically depicts this static version of the linear Gaussian model. The surrounding plate notation indicates that the conditional dependency structure applies independently for each of the $\tau = n$ observations.</p>
<figure class="center">
    <img src="/img/linear-gaussian/static_model.png" width="30%"/> 
</figure>

<p>With this model, we can analytically solve the marginal likelihood integral by using the <a href="https://en.wikipedia.org/wiki/Woodbury_matrix_identity">matrix inversion lemma</a> and by <a href="https://stats.stackexchange.com/questions/139522/completing-the-square-for-gaussian-multivariate-estimation">completing the square</a>. What we get is:</p>
<p>$$p(\mathbf{y}) \ = \ \mathcal{N}(\mathbf{0}, \mathbf{C}\mathbf{Q} \mathbf{C}^T + \mathbf{R}).$$</p>
<p>There is a degeneracy between the structure in $\mathbf{Q}$ and $\mathbf{C}$, and as a result, we can set $\mathbf{Q}=\mathbf{I}$ without loss of generality. Yet the learning problem of maximizing $p(\mathbf{y})$ with respect to parameters $\mathbf{C}$ and $\mathbf{R}$ still remains degenerate. Since our model $p(\mathbf{y})$ is a Gaussian, the optimal value for the covariance parameter is the sample covariance of the observations. Therefore, we could simply set $\mathbf{C}=\mathbf{0},$ and $\mathbf{R}$ to the sample covariance matrix. If we are to proceed with a more interesting solution, then we must restrict the matrix $\mathbf{R}$ in some shape or form, and this is a loss of generality. But by restricting $\mathbf{R}$, we arrive at interesting parameter settings for the observation and hidden processes.</p>
<p>If we restrict $\mathbf{R}$ to be diagonal, and set $\mathbf{Q}=\mathbf{I}$ as before, then our model is equivalent to maximum likelihood <em>factor analysis</em>. In this case, the covariance unique to each coordinate is represented in matrix $\mathbf{R}$ and the correlation structure is in $\mathbf{C}$. Factor analysis is invariant to a rescaling of the observations since the diagonal covariance $\mathbf{R}$ can easily adjust to this. However, rotating the data is problematic because of this diagonal restriction on the observation noise.</p>
<p>If we instead restrict $\mathbf{R}$ to be a multiple of the identity matrix, then we have a model known as <em>probabilistic principal component analysis</em>. This model is invariant to rotations of the observed data because the matrix $\mathbf{C}$ can correspondingly be rotated. Scaling the data will be problematic because the observation process has a spherical variance, i.e. scaling one coordinate and not another will result in different solutions to the inference and learning problems. If we take the limit $\mathbf{R} = \text{lim}_{\epsilon \rightarrow 0} \epsilon \mathbf{I}$, then the inference and learning process is equivalent to the standard PCA algorithm!</p>
<p>The Gaussian mixture model is slightly different because it incorporates a <em>discrete</em> hidden state variable. As before, we can achieve this in our model by making the following modification:</p>
<p>$$\begin{aligned} \mathbf{x} \ &amp;= \ \text{WTA}[\mathbf{w}] \quad \text{and} \ \mathbf{y} \ &amp;= \ \mathbf{C} \mathbf{x} + \mathbf{v}.  \end{aligned}$$</p>
<p>Similarly, if we take the limit as the observation noise becomes infinitesimal compared to the scale of the data, we get the standard vector quantization model!</p>
<h3 id="concluding-remarks">Concluding Remarks</h3>
<p>In this post, I showed how several variations of the linear Gaussian model are equivalent to classical unsupervised learning techniques like factor analysis, PCA, Gaussian mixtures, vector quantization, Kalman filters, and HMMs. Moreover, learning and inference in most of these models can be approached using the EM algorithm or approximations to it. I will cover this aspect of the discussion in much more detail at a later time, but the paper by Roweis and Ghahramani (1999) provides an in-depth description of the inference and learning procedures.</p>

      
      <div class="related">
</div>
      
    </div>
    
  </div>
</section>



<section class="section">
  <div class="container has-text-centered">
    <p>&copy; <a href="https://github.com/punit-haria">Punit Shah</a> 2017</p>
    
      <p>Powered by <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/ribice/kiss">Kiss</a>.</p>
    
  </div>
</section>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-187493056-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>





</body>
</html>

